{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **KEY_CONCEPTS**\n",
        "\n",
        "* **Token IDs**: Token IDs are numerical representations of words, subwords, or characters in the input text.\n",
        "They are produced by the tokenizer, which maps each word or subword to a unique integer based on the model's vocabulary. **Why Are They Needed?**\n",
        "Neural networks process numbers, not raw text. Token IDs provide a numerical encoding of text that the model can interpret.\n",
        "\n",
        "* We select a model - there is a tokenizer associated with it that transforms text to numerical-representation for it. i.e representations are specific to the tokenizer used\n",
        "\n",
        "* Example: For the sentence \"Transformers are amazing!\", BERTâ€™s tokenizer might split it as:\n",
        "\n",
        "* **[\"[CLS]\", \"transformers\", \"are\", \"amazing\", \"!\", \"[SEP]\"]**\n",
        "\n",
        "* Each token is mapped to a unique ID from the tokenizer's vocabulary. Example mapping:\n",
        "\n",
        "* **[101, 19081, 2024, 6429, 999, 102]**\n"
      ],
      "metadata": {
        "id": "r4w_xzIypPav"
      },
      "id": "r4w_xzIypPav"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Attention Mask**: A binary mask (1s and 0s) that indicates which tokens in the sequence should be attended to by the model.\n",
        "\n",
        "* Transformer models process sequences of fixed length. To handle varying input lengths:\n",
        "Shorter sequences: Are padded with a special padding token (e.g., [PAD]).\n",
        "\n",
        "* Attention mask: Ensures the model ignores these padding tokens during computation."
      ],
      "metadata": {
        "id": "Ny9Wa461rbUl"
      },
      "id": "Ny9Wa461rbUl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "YK8tyXtJr4Zz"
      },
      "id": "YK8tyXtJr4Zz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Logits (Raw Scores)**\n",
        "**What Are They?**\n",
        "Logits are the raw, unnormalized outputs of the model's final layer.\n",
        "For classification tasks, they represent the scores for each class before applying a normalization function like softmax.\n",
        "**Why Are They Important?**\n",
        "Logits are the model's predictions in their raw form.\n",
        "They are converted into probabilities using softmax for multi-class classification or sigmoid for multi-label classification."
      ],
      "metadata": {
        "id": "7V3BxH2ksJp3"
      },
      "id": "7V3BxH2ksJp3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Required Libraries**\n",
        "\n",
        "\n",
        "*   transformers: Library for state-of-the-art NLP models like BERT, GPT, and RoBERTa.\n",
        "Allows loading pre-trained models, tokenizers, and utilities for fine-tuning.\n",
        "*   For loading and preprocessing datasets from the Hugging Face Hub or local files.\n",
        "*   torch (PyTorch): A deep learning library for building and training models. Handles model training, GPU/CPU usage, and autograd for gradient computation.\n",
        "*   wandb (Weights & Biases): For experiment tracking and visualization.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aiX47UPYh-Hb"
      },
      "id": "aiX47UPYh-Hb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **PEFT (Parameter-Efficient Fine-Tuning)**\n",
        "PEFT is a set of techniques designed to fine-tune large pre-trained models more efficiently. Instead of updating all the parameters of a model (which can be computationally expensive and require a lot of memory), PEFT focuses on updating only a small subset of parameters. This makes fine-tuning faster, more memory-efficient, and accessible even on resource-constrained devices.\n",
        "\n",
        "**Key Concepts of PEFT**\n",
        "* Parameter-Efficiency: Only a small fraction of the model's parameters are updated during fine-tuning, reducing the computational and storage requirements.\n",
        "Common techniques include adapters, low-rank updates, and lightweight modules.\n",
        "\n",
        "* Low-Rank Adaptation (LoRA): LoRA injects low-rank matrices into the model's weights to adjust only a small portion of the model parameters during training.\n",
        "\n",
        "* This allows fine-tuning without modifying the entire model.\n",
        "\n",
        "**Advantages of PEFT**\n",
        "\n",
        "* Reduced Compute Requirements: Updates fewer parameters, enabling fine-tuning on smaller GPUs or CPUs.\n",
        "* Reuse of Pre-trained Models: Fine-tuning can be task-specific without modifying the core pre-trained model."
      ],
      "metadata": {
        "id": "qk8HZ8K6jc6U"
      },
      "id": "qk8HZ8K6jc6U"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accelerate :** Accelerate is a library by Hugging Face designed to simplify the process of scaling deep learning models and training to multiple GPUs, TPUs, or even CPUs. It provides abstractions to handle distributed training, model parallelism, and device placement seamlessly."
      ],
      "metadata": {
        "id": "99dSuhuakSz3"
      },
      "id": "99dSuhuakSz3"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers datasets peft torch accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgDb8p5cdlBL",
        "outputId": "035d987d-96e9-491f-d9e8-f01d63a5190d"
      },
      "id": "MgDb8p5cdlBL",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AutoTokenizer**\n",
        "\n",
        "\n",
        "* A utility for text tokenization.\n",
        "* Automatically loads the correct tokenizer associated with a pre-trained model specified by its name or path.\n",
        "Purpose:\n",
        "\n",
        "* Converts raw text into numerical tokens that a model can understand.\n",
        "* Handles tasks like splitting text into words, subwords, or characters and mapping them to integer IDs.\n",
        "* Reverses the process (from tokens back to text) for human-readable outputs."
      ],
      "metadata": {
        "id": "yvyJtk-nlKRO"
      },
      "id": "yvyJtk-nlKRO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXAMPLE OF TOKENIZER**"
      ],
      "metadata": {
        "id": "IJbyOnJllVGG"
      },
      "id": "IJbyOnJllVGG"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load tokenizer for a specific model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Tokenize text\n",
        "text = \"Transformers are amazing!\"\n",
        "encoded_input = tokenizer(text, return_tensors=\"pt\")  # PyTorch tensors\n",
        "print(encoded_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5w7dxB1lZjj",
        "outputId": "ec6da7ef-5ded-49d6-eec2-4b1858bcc51c"
      },
      "id": "t5w7dxB1lZjj",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101, 19081,  2024,  6429,   999,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AutoModelForSequenceClassification**\n",
        "\n",
        "* The AutoModelForSequenceClassification is a class from the Hugging Face transformers library designed specifically for sequence classification tasks.\n",
        "\n",
        "* It allows you to load a pre-trained transformer-based model (like BERT, RoBERTa, GPT, etc.) and modify it for classifying input text into predefined categories.\n",
        "\n",
        "* Takes tokenized inputs (from AutoTokenizer) and predicts class probabilities for a classification task.\n",
        "* Tasks include sentiment analysis, topic classification, or any problem where input text is mapped to predefined labels."
      ],
      "metadata": {
        "id": "HTZH6UOTl8Pi"
      },
      "id": "HTZH6UOTl8Pi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The AutoTokenizer and AutoModelForSequenceClassification**\n",
        "\n",
        "* Step 1: Tokenize Input Text\n",
        "\n",
        "The AutoTokenizer preprocesses raw text into token IDs and attention masks.\n",
        "\n",
        "* Step 2: Pass Tokens to the Model\n",
        "\n",
        "The tokenized inputs are fed into the AutoModelForSequenceClassification to produce logits (raw scores).\n",
        "\n",
        "* Step 3: Interpret Results\n",
        "\n",
        "The logits are converted into probabilities (e.g., using softmax) to classify the input into predefined categories."
      ],
      "metadata": {
        "id": "RdsMyUlumLVl"
      },
      "id": "RdsMyUlumLVl"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "Yr7eCiqCdduy"
      },
      "id": "Yr7eCiqCdduy",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "be94e6d6-4096-4d1a-aa58-5afd89f33bff",
      "metadata": {
        "id": "be94e6d6-4096-4d1a-aa58-5afd89f33bff"
      },
      "source": [
        "# Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "4ef8ea85-d04d-4217-99a3-21c446bf2ffa",
      "metadata": {
        "id": "4ef8ea85-d04d-4217-99a3-21c446bf2ffa"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict, Dataset\n",
        "# load_dataset:  function - Downloads and loads datasets from the Hugging Face Dataset Hub\n",
        "\n",
        "# DatasetDict: A dictionary-like object for managing multiple dataset splits (e.g., train, test, validation).\n",
        "\n",
        "# Dataset: Represents a single split of a dataset (e.g., train, test, or validation)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "# loads the tokenizer associated with a pre-trained model.\n",
        "# Purpose: Converts raw text into token IDs and performs padding/truncation as required by the model."
      ],
      "metadata": {
        "id": "V2ZOpOfZ0H11"
      },
      "id": "V2ZOpOfZ0H11",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig #Loads the configuration of a model (architecture, number of labels, etc.)."
      ],
      "metadata": {
        "id": "9PhJi5kS1uov"
      },
      "id": "9PhJi5kS1uov",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "#  Loads a pre-trained model for sequence classification tasks.\n",
        "\n",
        "#Purpose: Add a classification head to the transformer for tasks like sentiment analysis."
      ],
      "metadata": {
        "id": "Yehba0e010bK"
      },
      "id": "Yehba0e010bK",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "# A utility for dynamically padding batches to the same length during training.\n",
        "#Purpose: Ensures efficient processing of batches with varying input lengths."
      ],
      "metadata": {
        "id": "yqASmMkQ16O8"
      },
      "id": "yqASmMkQ16O8",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer # What it is: A high-level API for training and evaluating models."
      ],
      "metadata": {
        "id": "pva1E70A2FyX"
      },
      "id": "pva1E70A2FyX",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
        "\n",
        "# The peft library is designed to fine-tune large pre-trained models efficiently by freezing most of\n",
        "# the model's parameters and training only a small subset\n",
        "\n",
        "# Peft-Config: Configuration object for PEFT techniques.\n",
        "# Purpose: Defines parameters for techniques like LoRA, such as rank and learning rate.\n",
        "\n",
        "#What it is: Utility function to apply PEFT techniques to a model.\n",
        "#Purpose: Converts a standard model into a PEFT-enabled model.\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QOltws1A0J1E"
      },
      "id": "QOltws1A0J1E",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "aa6a4484-07d8-49dd-81ef-672105f53ebe",
      "metadata": {
        "id": "aa6a4484-07d8-49dd-81ef-672105f53ebe"
      },
      "source": [
        "### dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "fa9722d3-0609-4aea-9585-9aa2cfc1fc9a",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "fa9722d3-0609-4aea-9585-9aa2cfc1fc9a"
      },
      "outputs": [],
      "source": [
        "# # how dataset was generated\n",
        "\n",
        "# # load imdb data\n",
        "# imdb_dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# # define subsample size\n",
        "# N = 1000\n",
        "# # generate indexes for random subsample\n",
        "# rand_idx = np.random.randint(24999, size=N)\n",
        "\n",
        "# # extract train and test data\n",
        "# x_train = imdb_dataset['train'][rand_idx]['text']\n",
        "# y_train = imdb_dataset['train'][rand_idx]['label']\n",
        "\n",
        "# x_test = imdb_dataset['test'][rand_idx]['text']\n",
        "# y_test = imdb_dataset['test'][rand_idx]['label']\n",
        "\n",
        "# # create new dataset\n",
        "# dataset = DatasetDict({'train':Dataset.from_dict({'label':y_train,'text':x_train}),\n",
        "#                              'validation':Dataset.from_dict({'label':y_test,'text':x_test})})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "de226234-c521-4577-802c-0e7079ef4364",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de226234-c521-4577-802c-0e7079ef4364",
        "outputId": "7b1a0512-f866-4e41-8ae3-5cbcee96ba4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# load dataset\n",
        "dataset = load_dataset('shawhin/imdb-truncated') # Loads a dataset from the Hugging Face Hub\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "d5625faa-5fea-4334-bd38-b77de983d8a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5625faa-5fea-4334-bd38-b77de983d8a8",
        "outputId": "09728d1c-8912-4d5d-9bff-0c148b7a44f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# display % of training data with label=1\n",
        "np.array(dataset['train']['label']).sum()/len(dataset['train']['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3644c68d-9adf-48a4-90a2-8fd89555a302",
      "metadata": {
        "id": "3644c68d-9adf-48a4-90a2-8fd89555a302"
      },
      "source": [
        "### model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "a60dd1fe-8144-4678-b018-20891e49237a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a60dd1fe-8144-4678-b018-20891e49237a",
        "outputId": "19b5fd6e-ce67-47bf-94ac-1109021b5cfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_checkpoint = 'distilbert-base-uncased'\n",
        "\n",
        "# define label maps\n",
        "id2label = {0: \"Negative\", 1: \"Positive\"}\n",
        "label2id = {\"Negative\":0, \"Positive\":1}\n",
        "\n",
        "# generate classification model from model_checkpoint\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bc98609-873d-455c-bac4-155632cda484",
      "metadata": {
        "id": "4bc98609-873d-455c-bac4-155632cda484"
      },
      "source": [
        "### preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "7fe08707-657f-4e66-aa72-84899c54bf8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "7fe08707-657f-4e66-aa72-84899c54bf8d",
        "outputId": "589b90c3-8c08-48f5-f6ac-c6d9a63090d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nall input sequences must be the same length for efficient processing. If a modelâ€™s tokenizer doesn't \\nhave a padding token, the padding functionality wonâ€™t work as expected, so this code ensures that padding \\nis handled appropriately.\\n\\nif tokenizer.pad_token is None:: This checks if the tokenizer already has a pad_token defined. \\nThe pad token is used for padding input sequences to the same length in a batch, so the model can \\nprocess them efficiently. If the tokenizer does not have a padding token, it will be added.\\n\\ntokenizer.add_special_tokens({'pad_token': '[PAD]'}): This adds a special token, [PAD], to \\nthe tokenizer's vocabulary as the padding token. This ensures that sequences are padded to the \\nmaximum length in a batch using this token.\\n\\nmodel.resize_token_embeddings(len(tokenizer)): This adjusts the model's token \\nembedding layer to accommodate the new token added to the tokenizer (in this case, \\nthe [PAD] token). After adding new special tokens to the tokenizer, it's essential to \\nupdate the modelâ€™s embedding layer so that the model can handle the new tokens properly. \\nWithout this, the model would not be able to process the newly added padding token.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# create tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
        "\n",
        "# add pad token if none exists\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "all input sequences must be the same length for efficient processing. If a modelâ€™s tokenizer doesn't\n",
        "have a padding token, the padding functionality wonâ€™t work as expected, so this code ensures that padding\n",
        "is handled appropriately.\n",
        "\n",
        "if tokenizer.pad_token is None:: This checks if the tokenizer already has a pad_token defined.\n",
        "The pad token is used for padding input sequences to the same length in a batch, so the model can\n",
        "process them efficiently. If the tokenizer does not have a padding token, it will be added.\n",
        "\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'}): This adds a special token, [PAD], to\n",
        "the tokenizer's vocabulary as the padding token. This ensures that sequences are padded to the\n",
        "maximum length in a batch using this token.\n",
        "\n",
        "model.resize_token_embeddings(len(tokenizer)): This adjusts the model's token\n",
        "embedding layer to accommodate the new token added to the tokenizer (in this case,\n",
        "the [PAD] token). After adding new special tokens to the tokenizer, it's essential to\n",
        "update the modelâ€™s embedding layer so that the model can handle the new tokens properly.\n",
        "Without this, the model would not be able to process the newly added padding token.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "20f4adb9-ce8f-4f54-9b94-300c9daae1b8",
      "metadata": {
        "id": "20f4adb9-ce8f-4f54-9b94-300c9daae1b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d582aa74-98c3-4fba-bf17-0a97a50588ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n{\\n  'input_ids': np.array([101, 1024, 1025, 512, ... 0, 0, 0]),  # Token IDs (length = 512)\\n  'attention_mask': np.array([1, 1, 1, 1, ... 0, 0, 0])         # Attention Mask (length = 512)\\n}\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# create tokenize function\n",
        "def tokenize_function(examples):\n",
        "    # extract text\n",
        "    text = examples[\"text\"]\n",
        "\n",
        "    #tokenize and truncate text\n",
        "    tokenizer.truncation_side = \"left\"\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"np\", # okenized data in NumPy array format\n",
        "        truncation=True,\n",
        "        max_length=512 # maximum token length of the input text\n",
        "    )\n",
        "\n",
        "    return tokenized_inputs\n",
        "\n",
        "\"\"\"\n",
        "{\n",
        "  'input_ids': np.array([101, 1024, 1025, 512, ... 0, 0, 0]),  # Token IDs (length = 512)\n",
        "  'attention_mask': np.array([1, 1, 1, 1, ... 0, 0, 0])         # Attention Mask (length = 512)\n",
        "}\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "b7600bcd-7e93-4fb4-bd8d-ffc76bed1ac2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "8cc32a6f6e0e4da199d638aa76da1a83",
            "bb6c11a10b83405da57beb915a7b33d0",
            "904b1458f1af468ba9d7024ce21fbbdc",
            "8409f6cc61354e75aae8819bb3396469",
            "8419f4873a52493895e11596f8528760",
            "e199c2ca224842898c594a79a713d10c",
            "22217a998bc34d4b97dbe3a344f17bb7",
            "1eec8435077f4948ab0d33b071c3b587",
            "27966114a7284f8fa1807d397336d502",
            "d1694988365c476585dbc8001b26ec5a",
            "e1fd717e167b4ce58ffd1f1bee9877ff"
          ]
        },
        "id": "b7600bcd-7e93-4fb4-bd8d-ffc76bed1ac2",
        "outputId": "318303cd-8eab-42ed-ab79-ea4e7c44312f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cc32a6f6e0e4da199d638aa76da1a83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# tokenize training and validation datasets\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "3f8e85f9-1804-4f49-a783-4da59580ea1e",
      "metadata": {
        "id": "3f8e85f9-1804-4f49-a783-4da59580ea1e"
      },
      "outputs": [],
      "source": [
        "# create data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "# allows you to specify a variety of configurations for model training"
      ],
      "metadata": {
        "id": "rroQ0rEiAsxF"
      },
      "id": "rroQ0rEiAsxF",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3cd9a120-580d-470c-a981-7c7e22604865",
      "metadata": {
        "id": "3cd9a120-580d-470c-a981-7c7e22604865"
      },
      "source": [
        "### evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT8kkyuA7_N1",
        "outputId": "06d3dfae-da37-4868-b5d6-9ecea96cf07f"
      },
      "id": "AT8kkyuA7_N1",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "2a894819-2e9c-4a53-9790-32130c182bca",
      "metadata": {
        "id": "2a894819-2e9c-4a53-9790-32130c182bca"
      },
      "outputs": [],
      "source": [
        "# import accuracy evaluation metric\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "c07b9be2-a3f6-4b38-b9e8-6a2bc8aa945a",
      "metadata": {
        "id": "c07b9be2-a3f6-4b38-b9e8-6a2bc8aa945a"
      },
      "outputs": [],
      "source": [
        "# define an evaluation function to pass into trainer later\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47500035-a555-46e0-83dc-440586d96b7e",
      "metadata": {
        "id": "47500035-a555-46e0-83dc-440586d96b7e"
      },
      "source": [
        "### Apply untrained model to text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "8f3761c1-a297-45c8-882e-d74856259810",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f3761c1-a297-45c8-882e-d74856259810",
        "outputId": "dfe79579-849b-43d9-9233-2daad31fc8f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Untrained model predictions:\n",
            "----------------------------\n",
            "It was good. - Negative\n",
            "Not a fan, don't recommed. - Negative\n",
            "Better than the first one. - Positive\n",
            "This is not worth watching even once. - Negative\n",
            "This one is a pass. - Negative\n"
          ]
        }
      ],
      "source": [
        "# define list of examples\n",
        "text_list = [\"It was good.\", \"Not a fan, don't recommed.\", \"Better than the first one.\", \"This is not worth watching even once.\", \"This one is a pass.\"]\n",
        "\n",
        "print(\"Untrained model predictions:\")\n",
        "print(\"----------------------------\")\n",
        "for text in text_list:\n",
        "    # tokenize text\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "    # compute logits\n",
        "    logits = model(inputs).logits\n",
        "    # convert logits to label\n",
        "    predictions = torch.argmax(logits)\n",
        "\n",
        "    print(text + \" - \" + id2label[predictions.tolist()])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff356f78-c9fd-4f2b-8f5b-097cf29c1c08",
      "metadata": {
        "id": "ff356f78-c9fd-4f2b-8f5b-097cf29c1c08"
      },
      "source": [
        "### **Train model - LoRA (Low-Rank Adaptation) configuration for fine-tuning a model on a sequence classification task.**\n",
        "\n",
        "* task_type=\"SEQ_CLS\"\n",
        "task_type specifies the type of task you want to fine-tune the model for.\n",
        "\"SEQ_CLS\" stands for Sequence Classification\n",
        "*  r=4: r is the rank of the low-rank adaptation used in the LoRA method. It defines the number of low-rank matrices that will be added to the model to learn the new parameters.\n",
        "\n",
        "* A smaller value of r reduces the number of parameters being modified, making the fine-tuning process more efficient. In this case, r=4 means the model will introduce 4 low-rank matrices during the fine-tuning process.\n",
        "\n",
        "*  lora_alpha=32\n",
        "lora_alpha is a scaling factor applied to the low-rank matrices. This scaling helps control the influence of the adapted parameters.\n",
        "lora_alpha=32 means that the contribution of the low-rank adaptation matrices will be scaled by a factor of 32. This value influences how much the newly learned parameters will affect the model's performance.\n",
        "\n",
        "* lora_dropout=0.01\n",
        "lora_dropout applies dropout to the low-rank adaptation layers. Dropout is used to prevent overfitting by randomly setting some of the values in the adaptation matrices to zero during training.\n",
        "lora_dropout=0.01 means that there is a 1% chance for dropout to occur on the LoRA parameters. This ensures that the model doesnâ€™t overly rely on the adapted weights, which can improve generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "e4dde538-cd7f-4ab5-a96d-c30f3003822e",
      "metadata": {
        "id": "e4dde538-cd7f-4ab5-a96d-c30f3003822e"
      },
      "outputs": [],
      "source": [
        "peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
        "                        r=4,\n",
        "                        lora_alpha=32,\n",
        "                        lora_dropout=0.01,\n",
        "                        target_modules = ['q_lin'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "3e0d9408-9fc4-4bd3-8d35-4d8217fe01e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e0d9408-9fc4-4bd3-8d35-4d8217fe01e2",
        "outputId": "17daa0e9-ebd6-4ab2-f9e2-1c43cefcfaea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9307\n"
          ]
        }
      ],
      "source": [
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "lr = 1e-3\n",
        "batch_size = 4\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "6_JWpdDrDHMx"
      },
      "id": "6_JWpdDrDHMx",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "9244ed55-65a4-4c66-8388-55efd87bceb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9244ed55-65a4-4c66-8388-55efd87bceb8",
        "outputId": "4bf0cc23-3e46-470a-8d45-6a808eadb966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= model_checkpoint + \"-lora-text-classification\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "fc8bc705-5dd7-4305-a797-399b2b0fa2c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "fc8bc705-5dd7-4305-a797-399b2b0fa2c7",
        "outputId": "1d45d1c3-1971-4713-e44b-adbd7bce463c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-7fae756b6c66>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 07:17, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.470145</td>\n",
              "      <td>{'accuracy': 0.859}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.438600</td>\n",
              "      <td>0.401272</td>\n",
              "      <td>{'accuracy': 0.882}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.438600</td>\n",
              "      <td>0.588117</td>\n",
              "      <td>{'accuracy': 0.879}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.208000</td>\n",
              "      <td>0.658922</td>\n",
              "      <td>{'accuracy': 0.89}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.208000</td>\n",
              "      <td>0.841865</td>\n",
              "      <td>{'accuracy': 0.884}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.058300</td>\n",
              "      <td>0.868291</td>\n",
              "      <td>{'accuracy': 0.88}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.058300</td>\n",
              "      <td>0.987301</td>\n",
              "      <td>{'accuracy': 0.887}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.014700</td>\n",
              "      <td>1.003053</td>\n",
              "      <td>{'accuracy': 0.886}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.014700</td>\n",
              "      <td>1.035890</td>\n",
              "      <td>{'accuracy': 0.888}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>1.041113</td>\n",
              "      <td>{'accuracy': 0.884}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"{'accuracy': 0.859}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.882}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.879}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.89}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.884}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.88}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.887}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.886}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.888}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.884}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2500, training_loss=0.14450548000335695, metrics={'train_runtime': 439.5653, 'train_samples_per_second': 22.75, 'train_steps_per_second': 5.687, 'total_flos': 1112883852759936.0, 'train_loss': 0.14450548000335695, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# creater trainer object\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,# this will dynamically pad examples in each batch to be equal length\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# train model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f5664d1-9bd2-4ce1-bc24-cab5adf80f49",
      "metadata": {
        "id": "6f5664d1-9bd2-4ce1-bc24-cab5adf80f49"
      },
      "source": [
        "### Generate prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "e5dc029e-1c16-491d-a3f1-715f9e0adf52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5dc029e-1c16-491d-a3f1-715f9e0adf52",
        "outputId": "0af2dc36-f708-4afb-ee8d-375a9b74b09a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model predictions:\n",
            "--------------------------\n",
            "I love this product! It's amazing. - Positive\n",
            "The movie was fantastic. I really enjoyed it. - Positive\n",
            "I feel so happy with my new job. It's everything I hoped for. - Positive\n",
            "Such a wonderful day, everything went great! - Positive\n",
            "I'm really excited for the upcoming event. - Positive\n",
            "The movie was terrible. I hated it. - Negative\n",
            "I had a horrible experience with customer service. - Negative\n",
            "This is the worst restaurant I've ever been to. - Negative\n",
            "I am so frustrated with the current situation. - Negative\n",
            "The product arrived damaged, and the quality is poor. - Negative\n"
          ]
        }
      ],
      "source": [
        "model.to('cuda') # moving to mps for Mac (can alternatively do 'cpu')\n",
        "\n",
        "print(\"Trained model predictions:\")\n",
        "print(\"--------------------------\")\n",
        "text_list = [\n",
        "    # First 5 positive sentences\n",
        "    \"I love this product! It's amazing.\",\n",
        "    \"The movie was fantastic. I really enjoyed it.\",\n",
        "    \"I feel so happy with my new job. It's everything I hoped for.\",\n",
        "    \"Such a wonderful day, everything went great!\",\n",
        "    \"I'm really excited for the upcoming event.\",\n",
        "\n",
        "    # Next 5 negative sentences\n",
        "    \"The movie was terrible. I hated it.\",\n",
        "    \"I had a horrible experience with customer service.\",\n",
        "    \"This is the worst restaurant I've ever been to.\",\n",
        "    \"I am so frustrated with the current situation.\",\n",
        "    \"The product arrived damaged, and the quality is poor.\"\n",
        "]\n",
        "for text in text_list:\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cuda\") # moving to mps for Mac (can alternatively do 'cpu')\n",
        "\n",
        "    logits = model(inputs).logits\n",
        "    predictions = torch.max(logits,1).indices\n",
        "\n",
        "    print(text + \" - \" + id2label[predictions.tolist()[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "77c6ed42-8ec3-4343-9e42-405feac052ba",
      "metadata": {
        "id": "77c6ed42-8ec3-4343-9e42-405feac052ba"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8cc32a6f6e0e4da199d638aa76da1a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb6c11a10b83405da57beb915a7b33d0",
              "IPY_MODEL_904b1458f1af468ba9d7024ce21fbbdc",
              "IPY_MODEL_8409f6cc61354e75aae8819bb3396469"
            ],
            "layout": "IPY_MODEL_8419f4873a52493895e11596f8528760"
          }
        },
        "bb6c11a10b83405da57beb915a7b33d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e199c2ca224842898c594a79a713d10c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_22217a998bc34d4b97dbe3a344f17bb7",
            "value": "Map:â€‡100%"
          }
        },
        "904b1458f1af468ba9d7024ce21fbbdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1eec8435077f4948ab0d33b071c3b587",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27966114a7284f8fa1807d397336d502",
            "value": 1000
          }
        },
        "8409f6cc61354e75aae8819bb3396469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1694988365c476585dbc8001b26ec5a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e1fd717e167b4ce58ffd1f1bee9877ff",
            "value": "â€‡1000/1000â€‡[00:01&lt;00:00,â€‡612.68â€‡examples/s]"
          }
        },
        "8419f4873a52493895e11596f8528760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e199c2ca224842898c594a79a713d10c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22217a998bc34d4b97dbe3a344f17bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1eec8435077f4948ab0d33b071c3b587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27966114a7284f8fa1807d397336d502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1694988365c476585dbc8001b26ec5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1fd717e167b4ce58ffd1f1bee9877ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}